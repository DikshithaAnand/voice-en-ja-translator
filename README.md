# ğŸ™ï¸ Voice-Based English â†” Japanese Translator

## ğŸ“Œ Overview
This project is a **production-ready NLP and Speech Processing system** that performs **speech-to-speech translation** between **English and Japanese**.

Users can **record their voice directly in the browser**, and the system automatically:
1. Converts speech to text  
2. Translates the text  
3. Plays translated speech  
4. Displays confidence and quality metrics  
5. Highlights words in sync with audio  

The system is designed with **accuracy, transparency, and scalability** in mind.

---

## âœ¨ Key Features
- ğŸ¤ **Browser-based voice recording** (Start / Stop control)
- ğŸ§  **High-accuracy speech recognition using OpenAI Whisper**
- ğŸŒ **English â†” Japanese translation**
- ğŸ”Š **Text-to-speech output (in-memory, no files saved)**
- ğŸŸ¨ **Word-by-word highlighting synced with audio**
- ğŸ“Š **ASR Confidence score**
- ğŸ”‡ **Silence ratio analysis (audio quality indicator)**
- ğŸ–¥ï¸ **Clean and professional Streamlit UI**

---

## ğŸ§  Why This Project Is Different
Unlike basic speech apps, this system:
- Exposes **confidence and uncertainty**
- Avoids saving audio files (memory-safe & deployable)
- Uses **word-level timestamps** for precise UI sync
- Separates **audio capture, ASR, translation, and TTS** cleanly

This makes it suitable for **real-world applications**, demos, and interviews.

---

## ğŸ› ï¸ Tech Stack
- **Python**
- **Streamlit** â€“ UI & frontend
- **OpenAI Whisper** â€“ Speech recognition (offline, multilingual)
- **Google Translate API** â€“ Text translation
- **gTTS** â€“ Text-to-speech
- **NumPy & SciPy** â€“ Audio processing
- **Git & GitHub** â€“ Version control

---

## ğŸ”„ System Workflow

Voice Input
â†“
Silence Trimming
â†“
Speech Recognition (Whisper)
â†“
Text + Confidence + Word Timestamps
â†“
Translation (EN â†” JA)
â†“
Speech Output + UI Highlighting


---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/DikshithaAnand/voice-en-ja-translator.git
cd voice-en-ja-translator

```
2ï¸âƒ£ Create & activate virtual environment

```bash
python -m venv venv
venv\Scripts\activate

```

3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

4ï¸âƒ£ Run the application

```bash
streamlit run app.py
```


Open your browser at:

```bash
http://localhost:8501

```

ğŸ§ª How to Use

- Click ğŸ¤ Record

- Speak in English or Japanese

- Click Stop

- View:

   - Recognized text

   - Translation

   - Confidence & silence metrics

   - Word highlighting

- Listen to translated speech directly on screen

## ğŸ§  Speech Recognition

The system uses **OpenAI Whisper** for multilingual speech recognition.

Whisper was chosen because it:
- Works **offline**
- Handles **accents and pauses** effectively
- Provides **word-level timestamps**
- Supports **automatic language detection**

---

## ğŸ”‡ Audio Preprocessing

Before transcription, the audio is processed using **energy-based Voice Activity Detection (VAD)** to remove silence segments.

This preprocessing step improves:
- **Transcription accuracy**
- **Sentence completeness**
- **Confidence reliability**

## ğŸš€ Future Enhancements

Planned improvements to extend the systemâ€™s capabilities include:
- **Automatic language detection** to remove manual language selection
- **Conversation / multi-turn mode** for context-aware translation
- **Japanese romanization (Romaji) support** for language learners
- **Dark mode UI** for improved accessibility and user experience
- **Cloud deployment** using Streamlit Cloud or Docker
- **Support for additional languages** beyond English and Japanese

---

## ğŸ‘©â€ğŸ’» Author

**Dikshitha A**  
Computer Science Engineering  
Interests: **AI / ML Â· NLP Â· Speech Processing**  
GitHub: [https://github.com/DikshithaAnand](https://github.com/DikshithaAnand)

